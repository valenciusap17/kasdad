{"cells":[{"cell_type":"markdown","metadata":{"id":"0k_j9vD93i96"},"source":["<center>\n","<img src=\"https://drive.google.com/uc?id=1f1gGVI-rxcHjA90WEGNvvtSXF1pAxQwg\" alt=\"Fasilkom UI\" width=\"300\"/>\n","\n","CSGE603130 â€¢ Kecerdasan Artifisial dan Sains Data Dasar\n","\n","Semester Ganjil 2023/2024\n","\n","Fakultas Ilmu Komputer, Universitas Indonesia\n","\n","##**Lab *8*: *Clustering***\n","\n","###**Tenggat Waktu: XX Bulan 2023, 23.55 WIB**\n","</center>\n","\n","####**Ketentuan:**\n","\n","1. Dokumen *template* lab dengan format .ipynb dan dataset (jika dibutuhkan) telah disediakan di SCeLe\n","2. Jalankan kode pada dokumen .ipynb dan perhatikan dengan saksama apa yang potongan kode tersebut lakukan beserta dengan keluarannya. Jawablah **pertanyaan yang disisipkan** pada potongan program yang diberikan.\n","3. Dokumen Jupyter Notebook yang telah dilengkapi dengan jawaban dikumpulkan dengan format penamaan **Kelas_LabX_NPM_Nama.ipynb**. Contoh: A_Lab1_2006123456_Budi.ipynb\n","4. Kumpulkan dokumen tersebut pada submisi yang telah disediakan di SCeLe sesuai dengan kelas masing-masing sebelum **XX Bulan 2023, 23.55 WIB**. Keterlambatan pengumpulan akan dikenakan pinalti.\n","5. Lab ini dirancang sebagai **tugas mandiri**. Plagiarisme tidak diperkenankan dalam bentuk apapun. Adapun kolaborasi berupa diskusi (tanpa menyalin maupun mengambil jawaban orang lain) dan literasi masih diperbolehkan dengan mencantumkan kolaborator dan sumber.\n"]},{"cell_type":"markdown","metadata":{"id":"JnRUE1Ul62_R"},"source":["## **Pernyataan Integritas**\n","\n","Wajib diisi. Tanpa pernyataan integritas submisi akan dikenakan pinalti."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9tnfWWpN7vjq"},"outputs":[],"source":["# Isi dengan data diri Anda\n","NAMA = \"\"\n","KELAS = \"\"\n","NPM = \"\"\n","\n","# Isi dengan NPM teman yang berdiskusi dengan Anda\n","KOLABORATOR = []\n","\n","# Isi dengan sumber referensi yang Anda gunakan dalam mengerjakan\n","REFERENSI = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVEdteyu3hot","outputId":"df5112e7-929d-4cdc-f9fa-0c9a01438bc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saya,  dari kelas  dengan NPM , menyatakan bahwa seluruh jawaban pada pekerjaan ini murni saya kerjakan sendiri.\n","Saya tidak mencontek jawaban, memberikan jawaban, maupun menyalin dari sumber manapun.\n"," \n","Jika saya melanggar pernyataan tersebut, saya siap menerima konsekuensi apapun yang diberikan.\n","   ()\n"]}],"source":["PERNYATAAN_INTEGRITAS = \"Saya, %s dari kelas %s dengan NPM %s, menyatakan bahwa seluruh jawaban pada pekerjaan ini murni saya kerjakan sendiri.\\n\\\n","Saya tidak mencontek jawaban, memberikan jawaban, maupun menyalin dari sumber manapun.\\n \\\n","\\n\\\n","Jika saya melanggar pernyataan tersebut, saya siap menerima konsekuensi apapun yang diberikan.\\n   \\\n","(%s)\" % (NAMA, KELAS, NPM, NAMA)\n","\n","print(PERNYATAAN_INTEGRITAS)"]},{"cell_type":"markdown","source":["# Deskripsi Dataset"],"metadata":{"id":"3wKqMN6XWEer"}},{"cell_type":"markdown","source":["Penjelasan dataset:\n","\n","1. **mcg**: McGeoch's method for signal sequence recognition.\n","2. **gvh**: von Heijne's method for signal sequence recognition.\n","3. **lip**: von Heijne's Signal Peptidase II consensus sequence score. Binary attribute.\n","4. **chg**: Presence of charge on N-terminus of predicted lipoproteins. Binary attribute.\n","5. **aac**: score of discriminant analysis of the amino acid content of outer membrane and periplasmic proteins.\n","6. **alm1**: score of the ALOM membrane spanning region prediction program.\n","7. alm2: score of ALOM program after excluding putative cleavable signal regions from the sequence.\n","\n","Dataset source: https://archive.ics.uci.edu/dataset/39/ecoli"],"metadata":{"id":"0M1F3wZzaK4X"}},{"cell_type":"code","source":["# Impor library dan modul yang dibutuhkan pada tugas ini (boleh ditambahkan jika kurang)\n","import pandas as pd, numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","from yellowbrick.cluster import SilhouetteVisualizer\n","import matplotlib.cm as cm\n","import scipy.cluster.hierarchy as shc\n","from sklearn.cluster import AgglomerativeClustering\n","\n","from sklearn.decomposition import PCA"],"metadata":{"id":"jrdld02yYMhn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Preparing Dataset**"],"metadata":{"id":"wIqhVpnOVgwy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EK27FheIFqrt"},"outputs":[],"source":["# TODO: Open your dataset"]},{"cell_type":"markdown","source":["# **Clustering**"],"metadata":{"id":"81hCyWL9qwwf"}},{"cell_type":"markdown","source":["### **Pengertian**"],"metadata":{"id":"6xGiIGyWuVh4"}},{"cell_type":"markdown","source":["**Pengelompokan atau *clustering***, yang merupakan bagian dari unsupervised learning, melibatkan proses mengelompokkan sejumlah titik data ke dalam beberapa kelompok atau klaster sedemikian rupa sehingga objek dalam klaster yang sama memiliki tingkat kemiripan yang tinggi, sementara objek dalam klaster yang berbeda memiliki tingkat kemiripan yang rendah. Berbeda dengan supervised learning, clustering tidak memerlukan label yang terkait dengan setiap objek; sebaliknya, tujuannya adalah untuk menemukan pola dalam data, yang mungkin ada atau mungkin juga tidak (data mungkin tidak memiliki klaster yang jelas). Penting untuk dicatat bahwa algoritma pengelompokan tidak menjelaskan secara eksplisit makna dari setiap klaster, sehingga Anda perlu menginterpretasikannya sendiri, mungkin dengan melakukan visualisasi seperti yang akan dibahas dalam sesi lab kali ini."],"metadata":{"id":"0-60e0pEq05d"}},{"cell_type":"markdown","source":["### **Motivasi**"],"metadata":{"id":"soOmxz_ruanw"}},{"cell_type":"markdown","source":["Motivasi dari _unsupervised learning_ adalah untuk mengungkap pola, struktur, dan wawasan yang mungkin tersembunyi dalam data tanpa adanya petunjuk atau label yang jelas. Berikut adalah beberapa alasan mengapa _unsupervised learning_ sangat penting dan memiliki motivasi yang kuat:\n","\n","1. **Penemuan Pola Tersembunyi**: Seringkali, data dunia nyata tidak selalu dilengkapi dengan label yang menjelaskan apa yang ada di dalamnya. Dalam banyak kasus, kita mungkin tidak tahu apa yang harus dicari atau apa yang mungkin ada dalam data. _Unsupervised learning_ memungkinkan kita untuk mengeksplorasi data dan menemukan pola atau struktur yang mungkin tersembunyi, tanpa harus memiliki pengetahuan sebelumnya tentang apa yang harus dicari.\n","\n","2. **Segmentasi Data**: _Unsupervised learning_ memungkinkan kita untuk mengelompokkan data ke dalam kelompok atau klaster yang memiliki karakteristik atau kemiripan tertentu. Contohnya, dalam analisis pelanggan, kita dapat mengelompokkan pelanggan ke dalam segmen yang berbeda berdasarkan perilaku atau preferensi mereka. Ini dapat membantu perusahaan dalam mengarahkan strategi pemasaran yang lebih efektif.\n","\n","3. **Ekstraksi Fitur**: Algoritma _unsupervised learning_ dapat digunakan untuk mengekstraksi fitur-fitur penting dari data. Ini bermanfaat dalam mereduksi dimensi data, mengurangi kebisingan, atau mengungkapkan karakteristik yang relevan dalam dataset yang besar. Contohnya, dalam pengolahan citra, kita dapat menggunakan _dimensionality reduction_ untuk mengurangi jumlah fitur yang tidak relevan.\n","\n","4. **Anomali Detection**: _Unsupervised learning_ juga dapat digunakan untuk mendeteksi anomali dalam data. Ini berguna dalam kasus di mana kita mencoba menemukan data yang tidak biasa atau data yang tidak mengikuti pola mayoritas. Misalnya, dalam keamanan jaringan, kita dapat menggunakan _unsupervised learning_ untuk mendeteksi serangan siber yang tidak biasa.\n","\n","5. **Preprocessing Data**: _Unsupervised learning_ sering digunakan sebagai tahap awal dalam analisis data sebelum kita beralih ke metode _supervised learning_. Ini termasuk membersihkan data, mengisi data yang hilang, atau mengurangi dimensi data sebelum melatih model prediksi.\n","\n","6. **Penelitian Ilmiah dan Penemuan Baru**: Dalam beberapa kasus, _unsupervised learning_ digunakan dalam penelitian ilmiah untuk menemukan wawasan baru dalam data. Contohnya, dalam bidang ilmu genetika, analisis _unsupervised learning_ dapat membantu mengungkap pola baru dalam ekspresi gen atau perbedaan dalam populasi.\n","\n","Dalam rangkaian kasus di atas, _unsupervised learning_ memberikan cara untuk mengungkap dan memahami data yang mungkin sulit dipahami atau dianalisis dengan metode lain. Ini membuatnya menjadi alat yang kuat dalam berbagai bidang, termasuk ilmu data, kecerdasan buatan, pengolahan bahasa alami, penglihatan komputer, dan banyak lagi."],"metadata":{"id":"ArsnSfPiuRVN"}},{"cell_type":"markdown","source":["### **Jenis-jenis Algoritma**"],"metadata":{"id":"TAubCdLvvZI2"}},{"cell_type":"markdown","source":["Ada banyak algoritma _clustering_ yang digunakan untuk mengelompokkan data dalam berbagai konteks. Berikut beberapa algoritma _clustering_ yang umum digunakan:\n","\n","1. **K-Means**: Algoritma _K-Means_ adalah salah satu algoritma _clustering_ paling populer. Ini membagi data menjadi _K_ kluster di mana setiap titik data termasuk dalam kluster dengan pusat yang terdekat. Tujuan utamanya adalah untuk mengurangi variasi dalam kluster dan memaksimalkan variasi antara kluster.\n","\n","2. **Hierarchical Clustering**: Algoritma _clustering_ hierarki membangun hirarki kluster dengan menggabungkan atau membagi kluster dalam langkah-langkah yang berurutan. Ini menghasilkan pohon kluster yang dapat diwakili sebagai _dendrogram_, yang memungkinkan analisis tingkat hierarki.\n","\n","3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**: Algoritma _DBSCAN_ mengelompokkan data berdasarkan kerapatan. Ini mengidentifikasi kluster sebagai daerah di mana terdapat titik data yang cukup padat, sementara titik yang berada jauh dari kluster dianggap sebagai _noise_.\n","\n","4. **Agglomerative Clustering**: Ini adalah pendekatan hierarkis untuk pengelompokan di mana setiap titik data dianggap sebagai kluster tunggal dan kemudian secara berurutan menggabungkan kluster yang paling dekat satu sama lain hingga satu kluster besar terbentuk.\n","\n","Pilihan algoritma _clustering_ bergantung pada karakteristik data dan tujuan analisis. Setiap algoritma memiliki kelebihan dan kelemahan yang harus dipertimbangkan sesuai dengan kebutuhan Anda.\n","\n","Pada lab kali ini kita hanya akan membahas atau menggunakan beberapa algoritma yang dijelaskan pada slide yang tersedia yakni **K-Means** dan **Hierarchical**"],"metadata":{"id":"NHkSKYKsu7Q8"}},{"cell_type":"markdown","source":["# **Latihan Soal Praktis** [70]"],"metadata":{"id":"jKrAB_sTfxNA"}},{"cell_type":"markdown","source":["**Prapemrosesan data:**\n","Sebelum menjalankan algoritma clustering, pastikan Anda memahami dataset yang digunakan (minimal mengetahui fitur-fitur apa saja yang ada beserta tipe datanya). Selain itu, lakukan pre-processing pada data agar siap digunakan untuk clustering menggunakan K-Means. Berikut adalah hal-hal yang perlu dilakukan.\n","\n","- Handle missing value: Untuk menentukan klaster, diperlukan perhitungan jarak sedangkan missing value tidak bisa dihitung jaraknya. Contoh penanganannya adalah imputasi dengan mean/median tergantung bentuk distribusi data.\n","- Handle outliers: Algoritma K-Means sangat sensitif terhadap outliers (dapat memengaruhi klaster yang terbentuk). Oleh karena itu, jangan lupa untuk meng-handle outliers dengan heuristics tertentu (misalnya dengan metode capping).\n","- Standarisasi: K-Means juga sensitif terhadap rentang yang berbeda-beda dari atribut yang digunakan sehingga perlu dilakukan standarisasi data (misal dengan StandardScaler).\n","- Encoding: Kita bisa juga mengombinasikan atribut numerik dan kategorikal pada K-Means dengan cara mengkodekan atribut kategorikal ke dalam bentuk numerik (misalnya dengan LabelEncoder), kemudian memprosesnya seperti biasa (meskipun ada metode lain seperti K-Prototypes, tetapi hal tersebut di luar scope lab ini)."],"metadata":{"id":"iPaUUkTD_wDc"}},{"cell_type":"code","source":["# TODO: Do the inspection on the dataset and preprocess it"],"metadata":{"id":"8KX445fZYhid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: After preprocess the data, select some columns for clustering and assign it as X\n","X = None"],"metadata":{"id":"zhknHaBSYqn1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## K-Means Clustering [35]"],"metadata":{"id":"_DujQdQPf9OC"}},{"cell_type":"code","source":["# TODO: Anda dapat menambahkan nilai kemungkinan dari jumlah cluster yang akan dibuat untuk melihat kemungkinan pembentukkan cluster yang lebih baik.\n","num_of_cluster = [2, 3, 4, 5, 6, 7, 8]\n","\n","fig, ax = plt.subplots(4, 2, figsize=(20,10))\n","for k in num_of_cluster:\n","    # Create KMeans instance for different number of clusters\n","    clusterer = KMeans(n_clusters = k, n_init=10)\n","\n","    # Draw silhouette diagram\n","    q, mod = divmod(k, 2)\n","    visualizer = SilhouetteVisualizer(clusterer, colors = 'yellowbrick', ax = ax[q-1][mod])\n","    visualizer.fit(X)\n","\n","    # Compute silhoutte score\n","    # This gives a perspective into the density and separation of the formed clusters\n","    cluster_labels = clusterer.fit_predict(X)\n","    silhouette_avg = silhouette_score(X, cluster_labels)\n","    print(\n","        \"For n_clusters =\",\n","        k,\n","        \"The average silhouette_coefficient is :\",\n","        silhouette_avg,\n","    )"],"metadata":{"id":"_F7A8Jm34nwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Anda dapat menyesuaikan nilai dari n_clusters\n","kmeans = KMeans(n_clusters=3)\n","\n","cluster_assignment = kmeans.fit_predict(X)\n","data_with_clusters = pd.DataFrame(X.copy(), columns=('gvh', 'alm1'))\n","data_with_clusters['Clusters'] = cluster_assignment\n","data_with_clusters"],"metadata":{"id":"7mVpJNmChJ51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Tunjukkan plot berdasarkan hasil clustering yang sudah dilakukan."],"metadata":{"id":"ruWG79NPiug_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hierarchical Clustering [35]"],"metadata":{"id":"DrZnPXSkgCbz"}},{"cell_type":"code","source":["def plot_dendrogram(model, **kwargs):\n","    # Create linkage matrix and then plot the dendrogram\n","\n","    counts = np.zeros(model.children_.shape[0])\n","    n_samples = len(model.labels_)\n","    for i, merge in enumerate(model.children_):\n","        current_count = 0\n","        for child_idx in merge:\n","            if child_idx < n_samples:\n","                current_count += 1  # leaf node\n","            else:\n","                current_count += counts[child_idx - n_samples]\n","        counts[i] = current_count\n","\n","    linkage_matrix = np.column_stack(\n","        [model.children_, model.distances_, counts]\n","    ).astype(float)\n","\n","    # Plot the corresponding dendrogram\n","    shc.dendrogram(linkage_matrix, **kwargs)"],"metadata":{"id":"zA90LQSJ1Ygs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AgglomerativeClustering(distance_threshold = 0, n_clusters = None, linkage = 'ward', affinity = 'euclidean')\n","clustering = model.fit(X)\n","clustering.labels_"],"metadata":{"id":"iDDsP6sXw8YO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Tampilkan dendrogram dari data yang sudah ada."],"metadata":{"id":"ZQxaHqYz1wCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clustering = AgglomerativeClustering(n_clusters=3, linkage='ward', affinity='euclidean')\n","data_with_clusters['Agg_clusters'] = clustering.fit_predict(X)\n","data_with_clusters"],"metadata":{"id":"QID5xKGf2DYO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: Tunjukkan plot berdasarkan hasil clustering yang sudah dilakukan."],"metadata":{"id":"evIgJljP4COh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Latihan Soal Teoritis** [30]"],"metadata":{"id":"sMT077jMVw_c"}},{"cell_type":"markdown","source":["1. Dari hasil clustering yang telah dihasilkan menggunakan `KMeans`, berikan interpretasi mengenai _cluster-cluster_ yang terbentuk! [4]\n","\n","2. **Selain dari algoritma yang sudah diberitahukan pada bagian sebelumnya**, jelaskan 4 algoritma beserta cara kerjanya secara **singkat** dalam melakukan proses _clustering_! [4]\n","\n","3. Sebutkan 3 metrik evaluasi yang dapat digunakan untuk mengevaluasi hasil dari _clustering_ serta jelaskan masing-masing dari metrik tersebut! [6]\n","\n","4. Jelaskan cara menghitung *intra-cluster similarity* dan *inter-cluster dissimilarity*! Menurut pemahaman Anda, apakah yang membuat suatu klaster dianggap baik berdasarkan kedua metrik di atas? [6]\n","\n","5. Menurut Anda, mengapa algoritma K-Means tidak baik untuk dapat diterapkan pada data pengelompokkan yang tidak bersifat globular? Jelaskan alasannya berdasarkan cara perhitungan pada algoritma K-Means. [10]"],"metadata":{"id":"pJjbOfFCWGtT"}},{"cell_type":"markdown","source":["_Note: Untuk menjawab pertanyaan diatas, Anda dapat menambahkan beberapa text cell sesuai kebutuhan_"],"metadata":{"id":"0rcFUDiCib2M"}}],"metadata":{"colab":{"collapsed_sections":["0k_j9vD93i96"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}